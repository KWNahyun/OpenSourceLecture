{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"M861CpbeQSSI"},"outputs":[],"source":["import cv2\n","import time\n","import numpy as np\n","import os\n","import math\n","\n","\n","# 길이 계산 함수\n","def calculate_length(x1, y1, x2, y2):\n","    length = math.sqrt((x2-x1)**2 + (y2-y1)**2)\n","    return length\n","\n","# 영상 생성\n","def proc(module, video):\n","    # Choose the model files based on the specified module\n","    if module == \"coco\":\n","        protoFile = \"/content/drive/MyDrive/src/model/coco/pose_deploy_linevec.prototxt\"\n","        weightsFile = \"/content/drive/MyDrive/src/model/coco/pose_iter_440000.caffemodel\"\n","        nPoints = 18\n","        POSE_PAIRS = [[1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n","    elif module == \"mpi\":\n","        # Skip processing for mpi module\n","        return\n","\n","    # Set input size, threshold, and input video source\n","    inWidth = 368\n","    inHeight = 368\n","    threshold = 0.1\n","    input_source = \"/content/drive/MyDrive/src/input/\" + video\n","\n","    # Open the input video file\n","    cap = cv2.VideoCapture(input_source)\n","\n","    # Read the first frame\n","    hasFrame, frame = cap.read()\n","\n","    # Create a VideoWriter to save the processed video\n","    vid_writer = cv2.VideoWriter('/content/drive/MyDrive/src/output/' + video.split(\".\")[0] + \"_\"+ module + '.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame.shape[1],frame.shape[0]))\n","\n","    # Load the pre-trained pose estimation model\n","    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n","\n","    # 추가: 각도를 저장할 리스트\n","    length_list = []\n","\n","    # Main loop for processing frames\n","    while cv2.waitKey(1) \u003c 0:\n","        t = time.time()\n","\n","        # Read the next frame\n","        hasFrame, frame = cap.read()\n","        frameCopy = np.copy(frame)\n","\n","        # Check for the end of the video\n","        if not hasFrame:\n","            cv2.waitKey()\n","            break\n","\n","        # Get the frame dimensions\n","        frameWidth = frame.shape[1]\n","        frameHeight = frame.shape[0]\n","\n","        # Prepare the input blob for the neural network\n","        inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n","        net.setInput(inpBlob)\n","\n","        # Forward pass through the network\n","        output = net.forward()\n","\n","        # Get the dimensions of the output map\n","        H = output.shape[2]\n","        W = output.shape[3]\n","\n","        # Initialize a list to store keypoints\n","        points = []\n","\n","        # Process each keypoint\n","        for i in range(nPoints):\n","            probMap = output[0, i, :, :]\n","            minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n","            x = (frameWidth * point[0]) / W\n","            y = (frameHeight * point[1]) / H\n","\n","            # Check if the confidence is above the threshold\n","            if prob \u003e threshold:\n","                # Draw a circle and label the keypoint on the frame\n","                cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n","                cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n","                points.append((int(x), int(y)))\n","            else:\n","                points.append(None)\n","\n","        # 추가: 길이 계산 및 텍스트로 그리기, 리스트에 추가\n","        if points[0] and points[1]:\n","          length = calculate_length(points[0][0], points[0][1], points[1][0], points[1][1])\n","          length_text = \"Length: {:.2f}\".format(length)\n","          cv2.putText(frame, length_text, (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n","          length_list.append(length)\n","\n","        # Connect keypoints to form pose lines\n","        for pair in POSE_PAIRS:\n","            partA = pair[0]\n","            partB = pair[1]\n","            if points[partA] and points[partB]:\n","                cv2.line(frame, points[partA], points[partB], (0, 255, 255), 3, lineType=cv2.LINE_AA)\n","                cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n","                cv2.circle(frame, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n","\n","        # Display processing time on the frame\n","        cv2.putText(frame, \"Test Time = {:.2f} sec\".format(time.time() - t), (50, 50), cv2.FONT_HERSHEY_COMPLEX, .8, (255, 50, 0), 2, lineType=cv2.LINE_AA)\n","\n","        # Write the processed frame to the output video\n","        vid_writer.write(frame)\n","\n","    # Release the video writer\n","    vid_writer.release()\n","\n","if __name__ == '__main__':\n","    # Specify the modules to use\n","    module = [\"coco\"]\n","\n","    # Iterate over modules and input videos\n","    for i in module:\n","        for j in os.listdir(\"/content/drive/MyDrive/src/input/\"):\n","            # Check if the file is a video (mp4 or avi)\n","            if j[-3:] in ['mp4','avi']:\n","                # Process the video\n","                proc(i, j)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPEx5KUui58iQKAbHEXakvy","mount_file_id":"1C9xrr1i90_k9SckWTdZ4I1TYAw7CxkD-","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}